{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import relu, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_path = '/content/drive/MyDrive/Colab Notebooks/training.csv'\n",
    "training_data = pd.read_csv(training_file_path) \n",
    "training_data.columns\n",
    "\n",
    "test_file_path = '/content/drive/MyDrive/Colab Notebooks/testing.csv'\n",
    "test_data = pd.read_csv(test_file_path) \n",
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the training data\n",
    "X_trains = training_data.iloc[:, 1:]\n",
    "y_trains = training_data.iloc[:, 0]\n",
    "\n",
    "# Print the first few rows of the 'X' data\n",
    "print(X_trains.head())\n",
    "# Print the first few values of the 'y' data\n",
    "print(y_trains.head())\n",
    "\n",
    "# Extract the test data\n",
    "X_tests = test_data.iloc[:, 1:]\n",
    "y_tests = test_data.iloc[:, 0]\n",
    "\n",
    "# Print the first few rows of the 'X' data\n",
    "print(X_tests.head())\n",
    "# Print the first few values of the 'y' data\n",
    "print(y_tests.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X\n",
    "X_trains = np.array(X_trains)\n",
    "X_tests = np.array(X_tests)\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the 'y' data\n",
    "label_encoder.fit(y_trains)\n",
    "label_encoder.fit(y_tests)\n",
    "\n",
    "# Transform the 'y' data into encoded values\n",
    "y_trains= label_encoder.transform(y_trains)\n",
    "y_tests = label_encoder.transform(y_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Oversample the minority classes using SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "#  Undersample the majority class using RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "#  Apply SMOTE to oversample the minority classes in the training data\n",
    "X_trains, y_trains = smote.fit_resample(X_trains, y_trains)\n",
    "\n",
    "#  Apply RandomUnderSampler to undersample the majority class in the training data\n",
    "X_trains, y_trains = rus.fit_resample(X_trains, y_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RobustScaler object\n",
    "scaler = RobustScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the training data\n",
    "scaler.fit(X_trains)\n",
    "\n",
    "# Transform the training data\n",
    "X_trains = scaler.transform(X_trains)\n",
    "\n",
    "# Transform the testing data using the fitted scaler\n",
    "X_tests = scaler.transform(X_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of X_trains and y_trains\n",
    "print(f\"Shape of X_trains: {X_trains.shape}\")\n",
    "print(f\"Shape of y_trains: {y_trains.shape}\")\n",
    "\n",
    "# Data type of X_trains and y_trains\n",
    "print(f\"Data type of X_trains: {X_trains.dtype}\")\n",
    "print(f\"Data type of y_trains: {y_trains.dtype}\")\n",
    "\n",
    "# Print the first 10 rows of X_trains and y_trains\n",
    "print(f\"First 10 rows of X_trains: {X_trains[:10]}\")\n",
    "print(f\"First 10 rows of y_trains: {y_trains[:10]}\")\n",
    "\n",
    "# Shape of X_tests and y_tests\n",
    "print(f\"Shape of X_tests: {X_tests.shape}\")\n",
    "print(f\"Shape of y_tests: {y_tests.shape}\")\n",
    "\n",
    "# Data type of X_tests and y_tests\n",
    "print(f\"Data type of X_tests: {X_tests.dtype}\")\n",
    "print(f\"Data type of y_tests: {y_tests.dtype}\")\n",
    "\n",
    "# Print the first 10 rows of X_tests and y_tests\n",
    "print(f\"First 10 rows of X_tests: {X_tests[:10]}\")\n",
    "print(f\"First 10 rows of y_tests: {y_tests[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234) # for consistent results\n",
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.layers.InputLayer((28,)),\n",
    "        tf.keras.layers.Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01), name=\"L1\"),\n",
    "        tf.keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01), name=\"L2\"),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01), name=\"L3\"),\n",
    "        tf.keras.layers.Dense(6, activation=\"softmax\", name=\"L4\")\n",
    "    ], name = \"landCover_model\"\n",
    ")\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
